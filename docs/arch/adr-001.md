# Encryption of sensitive data
# Context

CSB receives, store and pass to terraform credentials needed for different tasks. For example, IaaS credentials used to connect to the account, with permissions to perform all the required administrative tasks, database server credentials, database credentials, etc.
Credentials needed, apart from the ones needed to connect to the IaaS account, are dictated by the variables defined in the different service offering definition files that make a brokerpak (yml file).
 
The credentials can be passed onto CSB in three different ways:
 - Environment variables
 - As parameters to a broker api request (e.g a cf create-service with a -c flag with options)
 - As a result (output) of a terraform operation (e.g admin password for a newly provisioned database, binding credentials, etc)

All these credentials are currently being passed around and stored in the CSB database in plain text.

Most CSB tables contain credentials of some type:

* Table `service_instance_details` in field `other_details`.
    This field contains json including IaaS credentials, admin credentials for provisioned resources generated by terraform, and any other custom credential that the service offering defines in its yml file.
* Table `provision_request_details` in field `request_details`.
    This field contains json including all credentials passed in the provision request (-c flag). IaaS credentials, admin credentials for servers where we want resources to be created and any other custom credential that the service offering defines in its yml file.
* Table `service_binding_credentials` in field `other_details`.
    This field contains json including all credentials passed in the binding request and the terraform outputs generated during binding. IaaS credentials, admin credentials for servers where we want resources to be created and any other custom credential that the service offering defines in its yml file.
* Table `terraform_deployments` in field `workspace`.
    This field contains the terraform workspace including the terraform state file. The terraform state has all variables replaced, meaning that all credentials reside there in plain text.
 
We are addressing the need to encrypt this data. We have several options we have been evaluating

## Key Management

1. They key could be generated by opsmanager/credhub and managed there. The advantage of autogeneration is that there is no chance of human error resulting in a loss of key and data loss.
1. Environment variable set by the operator. It is riskier and operators may dislike it. However is simpler at this point especially because there's a user base that have abandoned the tile and do `cf push`.
1. We could autogenerate it at startup/first use etc.  


## Data access

Currently the field names in the database and property/variable names in code don't reflect that credentials are being stored. Also, 

1. Accessor Methods: 
    * Data is in some scenarios is accessed via accessor methods that do json marshalling/unmarshalling, and sometimes these bits are scattered through the code.
    * The CSB code base is consistent in the usage of each property, meaning either we always unmarshal it for use or always pass it around marshalled.
    * refactor to use always accessor methods for these properties and do encryption decryption there is simple
1. There is support from the ORM used (GORM) to create custom datatypes and it is straight forward. This approach is transparent and does not need much modification in the code. We would need to create 1 datatype that encrypts/decrypts (potencially 2 datatypes, if we want to push json marshal/unmarshal, as not all the fields are used in the same way)  

## Other considerations

There is the possibility to identify among the request data, outputs and environment variables, which ones contain sensitive information.
There are some well defined environment variables (like the ones that contain IaaS credentials) that could be encrypted separately. 
Support to indentifying which variables are sensitive could be added in the brokerpaks (e.g. with a `sensitive` flag added to them)

Advantage:
* Not all data is encrypted, better troubleshooting

Disadvantage:
* Needs modification of the brokerpak definition schema. 
* Needs identification of the fields, which can be different within each service offering and plan in each brokerpak. There's the possibility of some property falling off our radar or a later addion to fail to configure correctly
* It still doesn't solve all problems, this approach couldn't be applied to an incoming request before logging it, for example.    

   
## Out of scope

Logging of sensitive data is not in scope at the moment. Although we have done some exploration around it, there is more we need to discuss and get user feedback on. It will be tackled as a separate item.
Key rotation: will be looked at separately after this is implemented.

# Decision

We decided to encrypt the aforementioned fields. 

We will use `2. Environment variable set by the operator` as first approach to key management. We acknowledge the risks but there is some evidence users would be willing to adopt this approach and makes it simpler and faster to get the core need of encrypting implemented, at least as a beta feature. It is also an approach that can be built on, and a second version could tackle key generation. Mitigations can be put in place to fail to start if the current key is not able to decrypt some test data. Or we can also store it in credhub from within CSB and fail to start if the key in the environment does not match credhub.


We will use `3. Accessor methods` to perform encryption/decryption. The reasons behind it are:
* It makes clear when and where credentials are being handled in plain text, as opposed of a custom datatype that would only be made visible in the model definition as an annotation.
* Decryption can be left out until credentials are actually needed and will be perform as soon as they are set, limiting the possibilities of leaking them with logging, under bad error handling etc. If we were to use the custom data type approach, encryption would happen as soon as we read from the database and delayed until we actually write to the database.
    
We will rename variables in the code to make clear which fields can contain sensitive data (as opposed to `other_details`)

We will consider renaming database fields.    

We will not look at the possibilities mentioned under [Other considerations](#o ther-considerations). Mostly because it is more complex, require more analysis at this point and could leak credentials if we somehow miss to identify a sensitive field in one of the services.    

The flow will be as follows
1. encryption key specified by an environment variable. As a first step the operator will be responsible of setting this value either through the tile or as an environment variable (through manifest or `cf set-env` command) on each `cf push` oepration performed.
2. All sensitive data will be encrypted/decrypted with that key within accessor methods

# Status
DRAFT

# Consequences

There is a risk that the operator will fail to provide the right encryption field and cause the loss of the data, and some data being encrypted with a different key. We can mitigate this by setting up some test values we can try to decrypt on start up, and fail to start if we can't. There is also the idea of continuing work on this and work on the solution to this mattters in a second iteration.

Accessing the data is not going to be as transparent as with a custom data type. However we think of this as an advantage in this context.

Troubleshooting becomes more challenging as all the parameters used are going to be encrypted in the database and eventually in logs.


 

